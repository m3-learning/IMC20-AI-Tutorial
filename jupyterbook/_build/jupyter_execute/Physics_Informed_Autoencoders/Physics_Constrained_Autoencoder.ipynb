{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxrwNCW3d_W5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Physics Constrained Autoencoders\n",
    "\n",
    "By Mary Ye$^1$, Joshua C. Agar$^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxrwNCW3d_W5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$^1$ Department of Computer science and Engineering, Lehigh University\n",
    "$^2$ Department of Mechanical Engineering and Mechanics, Drexel University\n",
    "\n",
    "- There are many times where you want to fit spectroscopic data to a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Classical fitting methods can be used but break down:\n",
    "  - When data is noisy\n",
    "  - There are multiple candidate models\n",
    "  - Data is high velocity\n",
    "  - Data is noisy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oWjlBBJzs73",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Imports Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: m3_learning in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (0.0.17)\n",
      "Collecting autopep8==2.0.0 (from m3_learning)\n",
      "  Using cached autopep8-2.0.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting BGlib==0.0.3 (from m3_learning)\n",
      "  Using cached BGlib-0.0.3-py2.py3-none-any.whl (189 kB)\n",
      "Collecting gdown==4.5.3 (from m3_learning)\n",
      "  Using cached gdown-4.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: h5py==3.7.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (3.7.0)\n",
      "Collecting imageio==2.22.3 (from m3_learning)\n",
      "  Using cached imageio-2.22.3-py3-none-any.whl (3.4 MB)\n",
      "Collecting jupyter==1.0.0 (from m3_learning)\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting matplotlib==3.6.2 (from m3_learning)\n",
      "  Using cached matplotlib-3.6.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "Collecting numpy==1.23.4 (from m3_learning)\n",
      "  Using cached numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting pandas==1.5.1 (from m3_learning)\n",
      "  Using cached pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "Collecting Pillow==9.3.0 (from m3_learning)\n",
      "  Using cached Pillow-9.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting protobuf==3.19.6 (from m3_learning)\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Collecting psutil==5.9.3 (from m3_learning)\n",
      "  Using cached psutil-5.9.3-cp310-cp310-win_amd64.whl (247 kB)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.2.2)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.2.8)\n",
      "Collecting pycodestyle==2.9.1 (from m3_learning)\n",
      "  Using cached pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting pycparser==2.21 (from m3_learning)\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting pycroscopy==0.62.1 (from m3_learning)\n",
      "  Downloading pycroscopy-0.62.1-py2.py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.2/48.2 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting Pygments==2.13.0 (from m3_learning)\n",
      "  Using cached Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (3.0.9)\n",
      "Collecting pyNSID==0.0.7 (from m3_learning)\n",
      "  Downloading pyNSID-0.0.7-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pyrsistent==0.19.2 (from m3_learning)\n",
      "  Using cached pyrsistent-0.19.2-cp310-cp310-win_amd64.whl (62 kB)\n",
      "Collecting PySocks==1.7.1 (from m3_learning)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (2.8.2)\n",
      "Collecting pytz==2022.6 (from m3_learning)\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Collecting pyUSID==0.0.10 (from m3_learning)\n",
      "  Using cached pyUSID-0.0.10-py2.py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: scikit-image==0.19.3 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.19.3)\n",
      "Collecting scikit-learn==1.1.3 (from m3_learning)\n",
      "  Using cached scikit_learn-1.1.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "Collecting scipy==1.9.3 (from m3_learning)\n",
      "  Using cached scipy-1.9.3-cp310-cp310-win_amd64.whl (40.1 MB)\n",
      "Collecting seaborn==0.12.1 (from m3_learning)\n",
      "  Using cached seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "Collecting sidpy==0.11 (from m3_learning)\n",
      "  Using cached sidpy-0.11-py2.py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.0)\n",
      "INFO: pip is looking at multiple versions of m3-learning to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting m3_learning\n",
      "  Downloading m3_learning-0.0.16-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.1/61.1 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting absl-py==1.3.0 (from m3_learning)\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting anyio==3.6.2 (from m3_learning)\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting argon2-cffi==21.3.0 (from m3_learning)\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting argon2-cffi-bindings==21.2.0 (from m3_learning)\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Collecting asttokens==2.1.0 (from m3_learning)\n",
      "  Using cached asttokens-2.1.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.6.3)\n",
      "Collecting attrs==22.1.0 (from m3_learning)\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.2.0)\n",
      "Collecting beautifulsoup4==4.11.1 (from m3_learning)\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting bleach==5.0.1 (from m3_learning)\n",
      "  Using cached bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "Collecting cachetools==5.2.0 (from m3_learning)\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting certifi==2022.9.24 (from m3_learning)\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting cffi==1.15.1 (from m3_learning)\n",
      "  Using cached cffi-1.15.1-cp310-cp310-win_amd64.whl (179 kB)\n",
      "Collecting charset-normalizer==2.1.1 (from m3_learning)\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: click==8.1.3 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle==2.2.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (2.2.0)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.4.6)\n",
      "Collecting contourpy==1.0.6 (from m3_learning)\n",
      "  Using cached contourpy-1.0.6-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Requirement already satisfied: cycler==0.11.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.11.0)\n",
      "Requirement already satisfied: cytoolz==0.12.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.12.0)\n",
      "Requirement already satisfied: dask==2022.10.2 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (2022.10.2)\n",
      "Collecting debugpy==1.6.3 (from m3_learning)\n",
      "  Using cached debugpy-1.6.3-cp310-cp310-win_amd64.whl (4.6 MB)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (5.1.1)\n",
      "Collecting defusedxml==0.7.1 (from m3_learning)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: distributed==2022.10.2 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (2022.10.2)\n",
      "Requirement already satisfied: entrypoints==0.4 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (1.2.0)\n",
      "Collecting fastjsonschema==2.16.2 (from m3_learning)\n",
      "  Using cached fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
      "Collecting filelock==3.8.0 (from m3_learning)\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting flatbuffers==22.10.26 (from m3_learning)\n",
      "  Using cached flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting fonttools==4.38.0 (from m3_learning)\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: fsspec==2022.10.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (2022.10.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.4.0)\n",
      "Collecting google-auth==2.14.0 (from m3_learning)\n",
      "  Using cached google_auth-2.14.0-py2.py3-none-any.whl (175 kB)\n",
      "Collecting google-auth-oauthlib==0.4.6 (from m3_learning)\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.2.0)\n",
      "Collecting grpcio==1.50.0 (from m3_learning)\n",
      "  Using cached grpcio-1.50.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Collecting HeapDict==1.0.1 (from m3_learning)\n",
      "  Using cached HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: idna==3.4 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (3.4)\n",
      "Requirement already satisfied: ipyfilechooser==0.6.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.6.0)\n",
      "Collecting ipykernel==6.17.0 (from m3_learning)\n",
      "  Using cached ipykernel-6.17.0-py3-none-any.whl (138 kB)\n",
      "Collecting ipython==8.6.0 (from m3_learning)\n",
      "  Using cached ipython-8.6.0-py3-none-any.whl (761 kB)\n",
      "Collecting ipython-genutils==0.2.0 (from m3_learning)\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ipywidgets==8.0.2 (from m3_learning)\n",
      "  Using cached ipywidgets-8.0.2-py3-none-any.whl (134 kB)\n",
      "Collecting jedi==0.18.1 (from m3_learning)\n",
      "  Using cached jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (3.1.2)\n",
      "Collecting joblib==1.2.0 (from m3_learning)\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting jsonschema==4.17.0 (from m3_learning)\n",
      "  Using cached jsonschema-4.17.0-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: jupyter-client==7.3.4 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (7.3.4)\n",
      "Collecting jupyter-console==6.4.4 (from m3_learning)\n",
      "  Using cached jupyter_console-6.4.4-py3-none-any.whl (22 kB)\n",
      "Collecting jupyter-server==1.21.0 (from m3_learning)\n",
      "  Using cached jupyter_server-1.21.0-py3-none-any.whl (346 kB)\n",
      "Collecting jupyter-core==4.11.2 (from m3_learning)\n",
      "  Using cached jupyter_core-4.11.2-py3-none-any.whl (88 kB)\n",
      "Collecting jupyterlab-pygments==0.2.2 (from m3_learning)\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting jupyterlab-widgets==3.0.3 (from m3_learning)\n",
      "  Using cached jupyterlab_widgets-3.0.3-py3-none-any.whl (384 kB)\n",
      "Collecting keras==2.10.0 (from m3_learning)\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.2 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.1.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.4.4)\n",
      "Collecting libclang==14.0.6 (from m3_learning)\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: locket==1.0.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.0.0)\n",
      "Requirement already satisfied: Markdown==3.4.1 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (3.4.1)\n",
      "Collecting MarkupSafe==2.1.1 (from m3_learning)\n",
      "  Using cached MarkupSafe-2.1.1-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.1.6)\n",
      "Collecting mistune==2.0.4 (from m3_learning)\n",
      "  Using cached mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msgpack==1.0.4 (from m3_learning)\n",
      "  Using cached msgpack-1.0.4-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting nbclassic==0.4.8 (from m3_learning)\n",
      "  Using cached nbclassic-0.4.8-py3-none-any.whl (9.8 MB)\n",
      "Collecting nbclient==0.7.0 (from m3_learning)\n",
      "  Using cached nbclient-0.7.0-py3-none-any.whl (71 kB)\n",
      "Collecting nbconvert==7.2.3 (from m3_learning)\n",
      "  Using cached nbconvert-7.2.3-py3-none-any.whl (273 kB)\n",
      "Collecting nbformat==5.7.0 (from m3_learning)\n",
      "  Using cached nbformat-5.7.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (1.5.6)\n",
      "Collecting networkx==2.8.8 (from m3_learning)\n",
      "  Using cached networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "Collecting notebook==6.5.2 (from m3_learning)\n",
      "  Using cached notebook-6.5.2-py3-none-any.whl (439 kB)\n",
      "Collecting notebook-shim==0.2.2 (from m3_learning)\n",
      "  Using cached notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy-groupies==0.9.7 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.9.7)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (3.2.2)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (3.3.0)\n",
      "Collecting packaging==21.3 (from m3_learning)\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting pandocfilters==1.5.0 (from m3_learning)\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: parso==0.8.3 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.8.3)\n",
      "Requirement already satisfied: partd==1.3.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.3.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (0.7.5)\n",
      "Collecting prometheus-client==0.15.0 (from m3_learning)\n",
      "  Using cached prometheus_client-0.15.0-py3-none-any.whl (60 kB)\n",
      "Collecting prompt-toolkit==3.0.31 (from m3_learning)\n",
      "  Using cached prompt_toolkit-3.0.31-py3-none-any.whl (382 kB)\n",
      "Requirement already satisfied: PyWavelets==1.4.1 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.4.1)\n",
      "Collecting PyYAML==6.0 (from m3_learning)\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting pyzmq==24.0.1 (from m3_learning)\n",
      "  Using cached pyzmq-24.0.1-cp310-cp310-win_amd64.whl (992 kB)\n",
      "Collecting qtconsole==5.4.0 (from m3_learning)\n",
      "  Using cached qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
      "Collecting QtPy==2.2.1 (from m3_learning)\n",
      "  Using cached QtPy-2.2.1-py3-none-any.whl (82 kB)\n",
      "Collecting requests==2.28.1 (from m3_learning)\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.3.1)\n",
      "Requirement already satisfied: rsa==4.9 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (4.9)\n",
      "Collecting Send2Trash==1.8.0 (from m3_learning)\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting sniffio==1.3.0 (from m3_learning)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: sortedcontainers==2.4.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (2.4.0)\n",
      "Collecting soupsieve==2.3.2.post1 (from m3_learning)\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting stack-data==0.6.0 (from m3_learning)\n",
      "  Using cached stack_data-0.6.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: tblib==1.7.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (1.7.0)\n",
      "Collecting tensorboard==2.10.1 (from m3_learning)\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting tensorboard-data-server==0.6.1 (from m3_learning)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit==1.8.1 (from m3_learning)\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorflow==2.10.0 (from m3_learning)\n",
      "  Using cached tensorflow-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Collecting tensorflow-estimator==2.10.0 (from m3_learning)\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting tensorflow-gpu==2.10.0 (from m3_learning)\n",
      "  Using cached tensorflow_gpu-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.27.0 (from m3_learning)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting termcolor==2.1.0 (from m3_learning)\n",
      "  Using cached termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting terminado==0.17.0 (from m3_learning)\n",
      "  Using cached terminado-0.17.0-py3-none-any.whl (16 kB)\n",
      "Collecting threadpoolctl==3.1.0 (from m3_learning)\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting tifffile==2022.10.10 (from m3_learning)\n",
      "  Using cached tifffile-2022.10.10-py3-none-any.whl (210 kB)\n",
      "Collecting tinycss2==1.2.1 (from m3_learning)\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting tomli==2.0.1 (from m3_learning)\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: toolz==0.12.0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (0.12.0)\n",
      "Collecting torch==1.13.0 (from m3_learning)\n",
      "  Using cached torch-1.13.0-cp310-cp310-win_amd64.whl (167.3 MB)\n",
      "Collecting torchvision==0.14.0 (from m3_learning)\n",
      "  Using cached torchvision-0.14.0-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: tornado==6.1 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (6.1)\n",
      "Collecting tqdm==4.64.1 (from m3_learning)\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting traitlets==5.5.0 (from m3_learning)\n",
      "  Using cached traitlets-5.5.0-py3-none-any.whl (107 kB)\n",
      "Collecting types-requests==2.28.11.2 (from m3_learning)\n",
      "  Using cached types_requests-2.28.11.2-py3-none-any.whl (14 kB)\n",
      "Collecting types-urllib3==1.26.25.1 (from m3_learning)\n",
      "  Using cached types_urllib3-1.26.25.1-py3-none-any.whl (14 kB)\n",
      "Collecting typing-extensions==4.4.0 (from m3_learning)\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting urllib3==1.26.12 (from m3_learning)\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting wcwidth==0.2.5 (from m3_learning)\n",
      "  Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting webencodings==0.5.1 (from m3_learning)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting websocket-client==1.4.2 (from m3_learning)\n",
      "  Using cached websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
      "Collecting Werkzeug==2.2.2 (from m3_learning)\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: wget==3.2 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from m3_learning) (3.2)\n",
      "Collecting widgetsnbextension==4.0.3 (from m3_learning)\n",
      "  Using cached widgetsnbextension-4.0.3-py3-none-any.whl (2.0 MB)\n",
      "Collecting wincertstore==0.2 (from m3_learning)\n",
      "  Using cached wincertstore-0.2-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting wrapt==1.14.1 (from m3_learning)\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: xlrd==2.0.1 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from m3_learning) (2.0.1)\n",
      "Collecting zenodopy==0.3.0 (from m3_learning)\n",
      "  Using cached zenodopy-0.3.0-py3-none-any.whl\n",
      "Collecting zict==2.2.0 (from m3_learning)\n",
      "  Using cached zict-2.2.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting zipfile38==0.0.3 (from m3_learning)\n",
      "  Using cached zipfile38-0.0.3-py3-none-any.whl\n",
      "Collecting hyperspy==1.7.4 (from m3_learning)\n",
      "  Downloading hyperspy-1.7.4-cp310-cp310-win_amd64.whl (32.6 MB)\n",
      "     ---------------------------------------- 32.6/32.6 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from astunparse==1.6.3->m3_learning) (0.38.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from gdown==4.5.3->m3_learning) (2.31.0)\n",
      "Requirement already satisfied: traits>=4.5.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (6.4.2)\n",
      "Requirement already satisfied: natsort in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (8.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (1.12)\n",
      "Requirement already satisfied: dill in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (0.3.7)\n",
      "Requirement already satisfied: ipyparallel in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (8.6.1)\n",
      "Requirement already satisfied: pint>=0.10 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (0.22)\n",
      "Requirement already satisfied: numexpr in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (2.8.5)\n",
      "Requirement already satisfied: sparse in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (0.14.0)\n",
      "Requirement already satisfied: prettytable in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (3.8.0)\n",
      "Requirement already satisfied: numba>=0.52 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from hyperspy==1.7.4->m3_learning) (0.56.4)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from hyperspy==1.7.4->m3_learning) (4.12.0)\n",
      "Requirement already satisfied: zarr>=2.9.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from hyperspy==1.7.4->m3_learning) (2.16.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from jupyter-core==4.11.2->m3_learning) (305.1)\n",
      "Collecting pywinpty (from jupyter-server==1.21.0->m3_learning)\n",
      "  Obtaining dependency information for pywinpty from https://files.pythonhosted.org/packages/e2/d2/9c69757e0c29e4d3bbc2b499800eb713e97cd8e080af1dd7cf9ab4e18626/pywinpty-2.0.11-cp310-none-win_amd64.whl.metadata\n",
      "  Downloading pywinpty-2.0.11-cp310-none-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from tensorboard==2.10.1->m3_learning) (68.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from importlib-metadata>=3.6->hyperspy==1.7.4->m3_learning) (3.16.2)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\jca92\\appdata\\roaming\\python\\python310\\site-packages (from numba>=0.52->hyperspy==1.7.4->m3_learning) (0.39.1)\n",
      "Requirement already satisfied: asciitree in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from zarr>=2.9.0->hyperspy==1.7.4->m3_learning) (0.3.3)\n",
      "Requirement already satisfied: fasteners in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from zarr>=2.9.0->hyperspy==1.7.4->m3_learning) (0.18)\n",
      "Requirement already satisfied: numcodecs>=0.10.0 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from zarr>=2.9.0->hyperspy==1.7.4->m3_learning) (0.11.0)\n",
      "INFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting requests[socks] (from gdown==4.5.3->m3_learning)\n",
      "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.5/62.5 kB 3.5 MB/s eta 0:00:00\n",
      "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.5/62.5 kB ? eta 0:00:00\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jca92\\.conda\\envs\\tutorials\\lib\\site-packages (from sympy->hyperspy==1.7.4->m3_learning) (1.3.0)\n",
      "Downloading pywinpty-2.0.11-cp310-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 1.4/1.4 MB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: zipfile38, wincertstore, webencodings, wcwidth, types-urllib3, tensorboard-plugin-wit, Send2Trash, pytz, msgpack, mistune, libclang, keras, ipython-genutils, HeapDict, flatbuffers, fastjsonschema, zict, wrapt, widgetsnbextension, websocket-client, urllib3, typing-extensions, types-requests, traitlets, tqdm, tomli, tinycss2, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, soupsieve, sniffio, pyzmq, PyYAML, pywinpty, PySocks, pyrsistent, Pygments, pycparser, pycodestyle, psutil, protobuf, prompt-toolkit, prometheus-client, Pillow, pandocfilters, packaging, numpy, networkx, MarkupSafe, jupyterlab-widgets, jupyterlab-pygments, joblib, jedi, grpcio, fonttools, filelock, defusedxml, debugpy, charset-normalizer, certifi, cachetools, bleach, attrs, asttokens, absl-py, Werkzeug, torch, tifffile, terminado, stack-data, scipy, requests, QtPy, pandas, jupyter-core, jsonschema, imageio, google-auth, contourpy, cffi, beautifulsoup4, autopep8, anyio, zenodopy, torchvision, scikit-learn, nbformat, matplotlib, ipython, argon2-cffi-bindings, seaborn, nbclient, ipykernel, google-auth-oauthlib, gdown, argon2-cffi, tensorboard, qtconsole, nbconvert, jupyter-console, ipywidgets, tensorflow-gpu, tensorflow, jupyter-server, hyperspy, sidpy, notebook-shim, pyUSID, nbclassic, notebook, BGlib, jupyter, m3_learning\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.6\n",
      "    Uninstalling wcwidth-0.2.6:\n",
      "      Successfully uninstalled wcwidth-0.2.6\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3\n",
      "    Uninstalling pytz-2023.3:\n",
      "      Successfully uninstalled pytz-2023.3\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.5\n",
      "    Uninstalling msgpack-1.0.5:\n",
      "      Successfully uninstalled msgpack-1.0.5\n",
      "  Attempting uninstall: libclang\n",
      "    Found existing installation: libclang 16.0.6\n",
      "    Uninstalling libclang-16.0.6:\n",
      "      Successfully uninstalled libclang-16.0.6\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "  Attempting uninstall: fastjsonschema\n",
      "    Found existing installation: fastjsonschema 2.18.0\n",
      "    Uninstalling fastjsonschema-2.18.0:\n",
      "      Successfully uninstalled fastjsonschema-2.18.0\n",
      "  Attempting uninstall: zict\n",
      "    Found existing installation: zict 3.0.0\n",
      "    Uninstalling zict-3.0.0:\n",
      "      Successfully uninstalled zict-3.0.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 4.0.8\n",
      "    Uninstalling widgetsnbextension-4.0.8:\n",
      "      Successfully uninstalled widgetsnbextension-4.0.8\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.9.0\n",
      "    Uninstalling traitlets-5.9.0:\n",
      "      Successfully uninstalled traitlets-5.9.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.2.0\n",
      "    Uninstalling threadpoolctl-3.2.0:\n",
      "      Successfully uninstalled threadpoolctl-3.2.0\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.3.0\n",
      "    Uninstalling termcolor-2.3.0:\n",
      "      Successfully uninstalled termcolor-2.3.0\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.31.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.31.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.31.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.1\n",
      "    Uninstalling tensorboard-data-server-0.7.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.5\n",
      "    Uninstalling soupsieve-2.5:\n",
      "      Successfully uninstalled soupsieve-2.5\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 23.2.1\n",
      "    Uninstalling pyzmq-23.2.1:\n",
      "      Successfully uninstalled pyzmq-23.2.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: sidpy 0.11 has a non-standard dependency specifier distributed>=2.0.0psutil. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of sidpy or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\jca92\\\\.conda\\\\envs\\\\tutorials\\\\Lib\\\\site-packages\\\\~aml\\\\_yaml.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install m3_learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0VKiyka604-",
    "outputId": "272c5a5b-36ac-4db0-b3d9-7b88401a9e13",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mm3_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtime_series_nn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Train, transform_nn\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mm3_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_fig\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mm3_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embeddings, latent_generator\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\m3_learning\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m viz\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m be\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\m3_learning\\be\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processing\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\m3_learning\\be\\processing.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m special\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBGlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m be \u001b[38;5;28;01mas\u001b[39;00m belib\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\tensorflow\\__init__.py:478\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# Do an eager load for Keras' code so that any function/method that needs to\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# happen at load time will trigger, eg registration of optimizers in the\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# SavedModel registry.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# See b/196254385 for more details.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m   \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\engine\\functional.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\dtensor\\layout_map.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazy_variable\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\engine\\base_layer.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_serialization\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_utils\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_serialization\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_impl\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialized_attributes\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;28;01mas\u001b[39;00m keras_load\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialized_attributes\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\saving\\saved_model\\load.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v2\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saved_metadata_pb2\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m versions_pb2\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\protobuf\\saved_metadata_pb2.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m versions_pb2 \u001b[38;5;28;01mas\u001b[39;00m keras_dot_protobuf_dot_versions__pb2\n\u001b[0;32m     19\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     20\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras/protobuf/saved_metadata.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m   ,\n\u001b[0;32m     26\u001b[0m   dependencies\u001b[38;5;241m=\u001b[39m[keras_dot_protobuf_dot_versions__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,])\n\u001b[0;32m     31\u001b[0m _SAVEDMETADATA \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     32\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSavedMetadata\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.SavedMetadata\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m175\u001b[39m,\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\keras\\protobuf\\versions_pb2.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m     18\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     19\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras/protobuf/versions.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x1d\u001b[39;00m\u001b[38;5;124mkeras/protobuf/versions.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x1d\u001b[39;00m\u001b[38;5;124mthird_party.py.keras.protobuf\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mK\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVersionDef\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;124mmin_consumer\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x15\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mbad_consumers\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     29\u001b[0m _VERSIONDEF \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersionDef\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.VersionDef\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m   filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m   file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     34\u001b[0m   containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m   fields\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 36\u001b[0m     \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproducer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthird_party.py.keras.protobuf.VersionDef.producer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     43\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     44\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_consumer\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.VersionDef.min_consumer\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     45\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     47\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     50\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     51\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad_consumers\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.VersionDef.bad_consumers\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     52\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     53\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     54\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     56\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     57\u001b[0m   ],\n\u001b[0;32m     58\u001b[0m   extensions\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     59\u001b[0m   ],\n\u001b[0;32m     60\u001b[0m   nested_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     61\u001b[0m   enum_types\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     62\u001b[0m   ],\n\u001b[0;32m     63\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     64\u001b[0m   is_extendable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m   syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     66\u001b[0m   extension_ranges\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     67\u001b[0m   oneofs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     68\u001b[0m   ],\n\u001b[0;32m     69\u001b[0m   serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     70\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m139\u001b[39m,\n\u001b[0;32m     71\u001b[0m )\n\u001b[0;32m     73\u001b[0m DESCRIPTOR\u001b[38;5;241m.\u001b[39mmessage_types_by_name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersionDef\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _VERSIONDEF\n\u001b[0;32m     74\u001b[0m _sym_db\u001b[38;5;241m.\u001b[39mRegisterFileDescriptor(DESCRIPTOR)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tutorials\\lib\\site-packages\\google\\protobuf\\descriptor.py:561\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    556\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    557\u001b[0m             is_extension, extension_scope, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    558\u001b[0m             serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    559\u001b[0m             has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    560\u001b[0m             file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _message\u001b[38;5;241m.\u001b[39mdefault_pool\u001b[38;5;241m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import math\n",
    "\n",
    "from m3_learning.nn.time_series_nn.nn_util import Train, transform_nn\n",
    "from m3_learning.viz.layout import layout_fig\n",
    "from m3_learning.viz.nn import embeddings, latent_generator\n",
    "from m3_learning.util.rand_util import rand_tensor\n",
    "from m3_learning.viz.style import set_style\n",
    "from m3_learning.nn.random import random_seed\n",
    "from m3_learning.viz.nn import embeddings, latent_generator\n",
    "set_style(\"printing\")\n",
    "random_seed(seed=42)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x-NFM-D0hpm",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generating some data based on the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x-NFM-D0hpm",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Define a non-linear function\n",
    "\n",
    "<center> $$ y = A sin(2\\theta f+ \\phi)$$ </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1XGgjpuIwTx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Sin_func:\n",
    "\n",
    "    \"\"\"\n",
    "    Class that computes the Sin function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_vector,\n",
    "        amp=[0, 1],\n",
    "        phase=[0, 1],\n",
    "        frequency=[0, 1],\n",
    "        size=(1, 1),\n",
    "        batch_size=1000,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x_vector:\n",
    "            sd (array, float): range for the standard deviation\n",
    "            mean (array, float): range for the mean\n",
    "            amp (array, float): range for the amplitude\n",
    "            size (tuple): Size of the array first index is number of channels, second is number of functions\n",
    "            verbose (bool): shows outputs\n",
    "        \"\"\"\n",
    "\n",
    "        self.x_vector = x_vector\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.amp = amp\n",
    "        self.amp_mean = torch.tensor(amp[0] + amp[1]) / 2\n",
    "        self.amp_sd = torch.sqrt(\n",
    "            torch.pow(torch.tensor(amp[1]) - torch.tensor(amp[0]), 2) / 12\n",
    "        )\n",
    "\n",
    "        self.phase = phase\n",
    "        self.phase_mean = torch.tensor(phase[0] + phase[1]) / 2\n",
    "        self.phase_sd = torch.sqrt(\n",
    "            torch.pow(torch.tensor(phase[1]) - torch.tensor(phase[0]), 2) / 12\n",
    "        )\n",
    "\n",
    "        self.frequency = frequency\n",
    "        self.frequency_mean = torch.tensor(frequency[0] + frequency[1]) / 2\n",
    "        self.frequency_sd = torch.sqrt(\n",
    "            torch.pow(torch.tensor(frequency[1]) -\n",
    "                      torch.tensor(frequency[0]), 2) / 12\n",
    "        )\n",
    "\n",
    "        self.size = size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def compute(self, params, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            self (object): Returns the instance itself.\n",
    "            device (string, optional) : Sets the device to do the computation. Default `cpu`, common option `cuda`\n",
    "\n",
    "        Returns: out (Tensor): spectra.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if len(params.size()) == 2:\n",
    "            params = torch.reshape(params, (params.shape[0], 3, -1))\n",
    "\n",
    "        out = torch.zeros(\n",
    "            (params.shape[0], self.x_vector.shape[0],\n",
    "             self.size[0], self.size[1])\n",
    "        )\n",
    "\n",
    "        params = params.to(device)\n",
    "\n",
    "        for i in range(self.size[1]):\n",
    "\n",
    "            if params.ndim == 4:\n",
    "                _amp = params[:, 0, 0, i]\n",
    "                _phase = params[:, 0, 1, i]\n",
    "                _frequency = params[:, 0, 2, i]\n",
    "\n",
    "            if params.ndim == 3:\n",
    "                _amp = params[:, 0, i]\n",
    "                _phase = params[:, 1, i]\n",
    "                _frequency = params[:, 2, i]\n",
    "\n",
    "            x_vector = (\n",
    "                torch.cat(params.shape[0] * [self.x_vector])\n",
    "                .reshape(params.shape[0], -1)\n",
    "                .to(device)\n",
    "            )\n",
    "            x_vector = torch.transpose(x_vector, 0, 1)  # .to(device)\n",
    "\n",
    "            _out = _amp * torch.sin(\n",
    "                2 * torch.tensor(np.pi) * _frequency * x_vector + _phase\n",
    "            )\n",
    "\n",
    "            out[:, :, 0, i] = torch.transpose(_out, 0, 1)\n",
    "\n",
    "        return (torch.sum(out, dim=3), out)\n",
    "\n",
    "    def sampler(self, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            device (str): device where computation happens\n",
    "\n",
    "        Returns:\n",
    "            out (Tensor) : Generated spectra\n",
    "            params (Tensor) : parameters used for generation\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        phase = rand_tensor(\n",
    "            min=self.phase[0],\n",
    "            max=self.phase[1],\n",
    "            size=(self.batch_size, self.size[0], self.size[1]),\n",
    "        )\n",
    "        frequency = rand_tensor(\n",
    "            min=self.frequency[0],\n",
    "            max=self.frequency[1],\n",
    "            size=(self.batch_size, self.size[0], self.size[1]),\n",
    "        )\n",
    "        amp = rand_tensor(\n",
    "            min=self.amp[0],\n",
    "            max=self.amp[1],\n",
    "            size=(self.batch_size, self.size[0], self.size[1]),\n",
    "        )\n",
    "        _params = torch.torch.stack((amp, phase, frequency))\n",
    "\n",
    "        _params = torch.atleast_2d(_params)\n",
    "        _params = torch.transpose(_params, 0, 1)\n",
    "        _params = torch.transpose(_params, 1, 2)\n",
    "\n",
    "        return (self.compute(_params, device=device), _params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziSPN95kMH96",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "constructor = Sin_func(\n",
    "    amp=[0.2, 1],  # Sets the amplitude\n",
    "    phase=[0, 2 * np.pi],  # Sets the phase\n",
    "    frequency=[0.1, 0.5],  # Sets the frequency\n",
    "    x_vector=torch.linspace(0, np.pi, 100),  # Sets the x_vector\n",
    "    batch_size=10000,\n",
    ")  # number of samples to generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLaP-ksVM-Vv",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# initializes the constructor\n",
    "output = constructor.sampler()\n",
    "\n",
    "# grabs the parameters and the spectra\n",
    "spectra, params = output\n",
    "\n",
    "# This grabs the sum of all spectral and the individual spectra if they exist\n",
    "spectra_full, spectras = spectra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fpr1aijpYuO",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualize examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "h7CLS6s0NLT4",
    "outputId": "88ed9e63-6940-41b3-cabf-1cdfce3a693c"
   },
   "outputs": [],
   "source": [
    "rand = np.random.randint(0, 10000)\n",
    "plt.plot(spectras[rand, :, 0].cpu(), \"b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HASHdT3YPCe3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Network Autoencoders\n",
    "\n",
    "- It is important to consider the temporal domain\n",
    "- This can be improved by using a recurrent neural network that processes each time step sequentially.\n",
    "- To add an understanding about the short and long term information in the data you can add memory and forget logic as a learnable parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HASHdT3YPCe3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://github.com/jagar2/AI_For_Atoms_Autoencoder_Tutorial/blob/main/img/Autoencoder_Med.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMyui0C1PCe3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://github.com/jagar2/AI_For_Atoms_Autoencoder_Tutorial/blob/main/img/LSTM%20Node.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfc1_DKg89Il",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6sCf2kDPCe3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, 12, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(24, 12, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(24, self.latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        (x, (_, __)) = self.lstm(x)\n",
    "        (x, (_, __)) = self.lstm2(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(self.latent_dim, 12,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(24, 12, batch_first=True, bidirectional=True)\n",
    "        self.tdd = nn.Conv1d(24, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, None]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = x.repeat([1, 100, 1])\n",
    "        (x, (_, __)) = self.lstm(x)\n",
    "        (x, (_, __)) = self.lstm2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.tdd(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxBAeRAjn3j3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # encode\n",
    "\n",
    "        embedding = self.encoder(x)\n",
    "\n",
    "        # decode\n",
    "\n",
    "        predicted = self.decoder(embedding)\n",
    "\n",
    "        return predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaRlMbfttiaZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since we know there are intrinsically 3 latent dimensions let's try and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mm-1aG9rPCe4",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "latent_dim = 3\n",
    "\n",
    "encoder = Encoder(latent_dim=latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim=latent_dim).to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5t5hvfQPCe4",
    "outputId": "e17abdb6-4993-416c-c751-1e1b48cdcab0",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# views the model\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0jldeW4OZSb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# constructs a dataloader for training\n",
    "\n",
    "dataloader = DataLoader(spectra_full, batch_size=512,\n",
    "                        shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eijf5211Qa7h",
    "outputId": "fb0e95a7-da1f-455c-d670-aa7c02c622ac",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# trains the model\n",
    "\n",
    "random_seed(seed=42)\n",
    "\n",
    "Train(\n",
    "    model, encoder, decoder, dataloader, optimizer, 500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfcYvUY4wjMz",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualize the reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8fpD4ncv29H",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# computes an example reconstruction for a mini batch\n",
    "\n",
    "(encoded_, decoded_) = transform_nn(next(iter(dataloader)), encoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "NA20y3ijVcwc",
    "outputId": "8aa05dc5-c8cd-4a09-b119-70f58fe1e0c2",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# plots a random example of the original and predicted spectra\n",
    "\n",
    "rand = np.random.randint(0, 512)\n",
    "plt.plot(spectras[rand, :, 0].cpu(), \"b\", label=\"Original\")\n",
    "plt.plot(decoded_[rand].squeeze(), \"r\", label=\"Generated\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXjwNNaSz5MS",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generating Validation Data\n",
    "\n",
    "- We want to generate a hyperspectral image\n",
    "- This can be done by taking the RGB values of an image and using them as parameters for a function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJLKait50MP6",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Loads and image of my dog Nala\n",
    "\n",
    "- Painting by _Irene Dogmatic_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MG4YZi2tfeSi",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Loads dog image\n",
    "\n",
    "image = io.imread(\n",
    "    \"https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/nala.jpg?raw=true\"\n",
    ")\n",
    "\n",
    "# Crops dog image\n",
    "\n",
    "image = image[200:1900:20, 100:1500:20] / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUpSmdfP0Ysv",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Displays the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "ud8Peh1Sd9CJ",
    "outputId": "b0a04e29-83b9-4bc7-d276-ab523bde36eb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generates the data from RGB sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBKSfOPExI3q",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Converts the image into parameters within the generated range\n",
    "\n",
    "nala_params = np.atleast_3d(image.reshape(-1, 3))\n",
    "\n",
    "nala_amp = torch.tensor(nala_params[:, 0, 0] * 0.8 + 0.2)\n",
    "nala_phase = torch.tensor(nala_params[:, 1, 0] * 2 * np.pi)\n",
    "nala_frequency = torch.tensor(nala_params[:, 2, 0] * 0.5 + 0.1)\n",
    "\n",
    "_nala_params = torch.torch.stack((nala_amp, nala_phase, nala_frequency))\n",
    "\n",
    "_nala_params = torch.atleast_3d(_nala_params)\n",
    "_nala_params = torch.transpose(_nala_params, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_zD6eocyTO8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# builds the spectra from the parameters\n",
    "\n",
    "(nala_spectra, _) = constructor.compute(_nala_params)\n",
    "\n",
    "# generated the encoded representation and decoded spectra\n",
    "\n",
    "(nala_encoded_, nala_decoded_) = transform_nn(nala_spectra, encoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "QIIx6V00yW2A",
    "outputId": "2e3117ae-5829-403a-90b3-72a2b3cd8f08",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# plots a random example of the original and predicted spectra\n",
    "\n",
    "rand = np.random.randint(0, nala_spectra.shape[0])\n",
    "plt.plot(nala_spectra[rand, :, 0].cpu(), \"b\", label=\"Original\")\n",
    "plt.plot(nala_decoded_[rand].squeeze(), \"r\", label=\"Generated\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualize the learned results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "pTGCN2t0yfc5",
    "outputId": "cd8014ca-117d-4744-95d8-becce3f56df5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the learned embeddings\n",
    "embeddings(nala_encoded_, shape_=image.shape[0:2], figsize=(5, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "G3ebdrvlyWvg",
    "outputId": "1c1e864c-6bd3-492b-8cca-5f5058342917",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the actual RGB channels.\n",
    "embeddings(_nala_params.reshape(-1, 3),\n",
    "           shape_=image.shape[0:2], figsize=(5, 1.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTptJUrR3ILQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **There is minimal resemblance to the true features**\n",
    "\n",
    "- This is unsurprising because there are no rules that define what the embedding should look like.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyeX8d_L3RoO",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's try a bigger model\n",
    "\n",
    "### Builds the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD9AHYqh8rpD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "latent_dim = 12\n",
    "\n",
    "encoder = Encoder(latent_dim=latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim=latent_dim).to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnCrCI4_8rpD",
    "outputId": "0534483a-a3e3-449c-ab2b-b612d3816cd9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# views the model\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_DuA4Ta8rpE",
    "outputId": "ce01e347-efaa-4829-fbe6-2aca505e9f5b",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# trains the model\n",
    "\n",
    "torch.manual_seed(0)\n",
    "Train(\n",
    "    model, encoder, decoder, dataloader, optimizer, 500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0rH1RJF8rpF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualize the reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQiIfRNr8rpF",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# computes an example reconstruction for a minibatch\n",
    "\n",
    "(encoded_, decoded_) = transform_nn(next(iter(dataloader)), encoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "Vw39umex8rpF",
    "outputId": "dd15aa3c-8691-4a82-c809-28c6b2cb76d6",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# plots a random example of the original and predicted spectra\n",
    "\n",
    "rand = np.random.randint(0, 512)\n",
    "plt.plot(spectras[rand, :, 0].cpu(), \"b\", label=\"Original\")\n",
    "plt.plot(decoded_[rand].squeeze(), \"r\", label=\"Generated\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9FvEzGbADuL",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Reconstruction is slightly better but just more overfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualize the learned results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6Y5kHZx8rpH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# builds the spectra from the parameters\n",
    "\n",
    "(nala_spectra, _) = constructor.compute(_nala_params)\n",
    "\n",
    "# generated the encoded representation and decoded spectra\n",
    "\n",
    "(nala_encoded_, nala_decoded_) = transform_nn(nala_spectra, encoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "Eb1YE0RE8rpH",
    "outputId": "6b31b706-2507-46b5-f64c-069c3ea7cad9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# plots a random example of the original and predicted spectra\n",
    "\n",
    "rand = np.random.randint(0, nala_spectra.shape[0])\n",
    "plt.plot(nala_spectra[rand, :, 0].cpu(), \"b\", label=\"Original\")\n",
    "plt.plot(nala_decoded_[rand].squeeze(), \"r\", label=\"Generated\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "s2BSXlJC8rpH",
    "outputId": "179e9e48-f3b9-4673-85f7-e9e94479d8ea",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the learned embeddings\n",
    "\n",
    "embeddings(nala_encoded_, shape_=image.shape[0:2], figsize=(5, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "5FrPP3-Y8rpH",
    "outputId": "4a156602-00f5-4ee8-9f86-1356f43760e7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the actual RGB channels.\n",
    "embeddings(_nala_params.reshape(-1, 3),\n",
    "           shape_=image.shape[0:2], figsize=(4, 1.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEqt9hGT8rpI",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Now there are just more features but no resemblance between the parameters.**\n",
    "- It would be impossible to have any resemblance to the features since it is overcomplete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glpKkqPCAjIR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Physics constrained neural network\n",
    "\n",
    "### Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VObnDnsnVcs2",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class DensePhysLarger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_vector,\n",
    "        model,\n",
    "        dense_params=3,\n",
    "        verbose=False,\n",
    "        device=\"cuda\",\n",
    "        num_channels=1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x_vector: The vector of values for x\n",
    "            model: the empirical function to fit\n",
    "            dense_params: number of output parameters to the model\n",
    "            verbose: sets if the model is verbose\n",
    "            device: device where the model will run\n",
    "            num_channels: number of channels in the input\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.dense_params = dense_params\n",
    "        self.x_vector = x_vector\n",
    "        self.verbose = verbose\n",
    "        self.num_channels = num_channels\n",
    "        self.device = device\n",
    "        self.model_params = kwargs.get(\"model_params\")\n",
    "        # (self.x_vector, size=(num_channels, dense_params // self.model_params))\n",
    "        self.model = model\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        n = 4\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "\n",
    "        # Input block of 1d convolution\n",
    "\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.num_channels,\n",
    "                      out_channels=8 * n, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8 * n, out_channels=6 * n, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6 * n, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_x1_shape = self.hidden_x1(\n",
    "            torch.zeros(1, self.num_channels, self.x_vector.shape[0])\n",
    "        ).shape\n",
    "\n",
    "        # fully connected block\n",
    "\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(self.hidden_x1_shape[1] * self.hidden_x1_shape[2], 20),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # out of size 20\n",
    "\n",
    "        self.hidden_xfc_shape = self.hidden_xfc(\n",
    "            torch.zeros(1, self.hidden_x1_shape[1] * self.hidden_x1_shape[2])\n",
    "        ).shape\n",
    "\n",
    "        # 2nd block of 1d-conv layers\n",
    "\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=1, out_channels=4 * n, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4 * n, out_channels=4 * n, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4 * n, out_channels=4 * n, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4 * n, out_channels=4 * n, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4 * n, out_channels=4 * n, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4 * n, out_channels=4 * n, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=4 * n, out_channels=2 * n, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2 * n, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.hidden_x2_shape = self.hidden_x2(\n",
    "            torch.zeros(\n",
    "                (\n",
    "                    self.hidden_xfc_shape[0],\n",
    "                    1,\n",
    "                    self.hidden_x1_shape[1] * self.hidden_x1_shape[2],\n",
    "                )\n",
    "            )\n",
    "        ).shape\n",
    "\n",
    "        # Flatten layer\n",
    "\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        # Final embedding block - Output 4 values - linear\n",
    "\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                self.hidden_x2_shape[1] * self.hidden_x2_shape[2]\n",
    "                + self.hidden_xfc_shape[1],\n",
    "                16,\n",
    "            ),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(8, self.dense_params),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "\n",
    "        x = self.hidden_x1(x)\n",
    "        xfc = torch.reshape(x, (x.shape[0], -1))  # batch size, features\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "        x = torch.reshape(\n",
    "            x, (x.shape[0], 1, self.hidden_x1_shape[1]\n",
    "                * self.hidden_x1_shape[2])\n",
    "        )\n",
    "        x = self.hidden_x2(x)\n",
    "        cnn_flat = self.flatten_layer(x)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)  # merge dense and 1d conv.\n",
    "\n",
    "        embedding = self.hidden_embedding(encoded)  # output is 3 parameters\n",
    "\n",
    "        embedding = torch.reshape(embedding, (embedding.shape[0], 3, -1))\n",
    "\n",
    "        embedding[:, 0, :] = (\n",
    "            embedding[:, 0, :] * self.model.amp_sd + self.model.amp_mean\n",
    "        )\n",
    "        embedding[:, 1, :] = (\n",
    "            embedding[:, 1, :] * self.model.phase_sd + self.model.phase_mean\n",
    "        )\n",
    "        embedding[:, 2, :] = (\n",
    "            embedding[:, 2, :] * self.model.frequency_sd +\n",
    "            self.model.frequency_mean\n",
    "        )\n",
    "\n",
    "        embedding = torch.reshape(embedding, (embedding.shape[0], -1))\n",
    "\n",
    "        embedding = torch.abs(embedding)\n",
    "        self.embed = embedding\n",
    "\n",
    "        (out, _) = self.model.compute(embedding, device=self.device)\n",
    "\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = torch.atleast_3d(out)\n",
    "\n",
    "        return (out.to(self.device), embedding.to(self.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKrvL1bxVcjn",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_vector = torch.linspace(0, 10, 100)\n",
    "\n",
    "model = DensePhysLarger(\n",
    "    x_vector, constructor, dense_params=3, model_params=3, verbose=False\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4QtxjDaXm0s",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# builds the dataloader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    torch.transpose(spectra_full, 1, 2), batch_size=512, shuffle=True, num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDHXFqcjfNy5",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    total_num = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for train_batch in dataloader:\n",
    "        pred, _ = model(train_batch.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_func(train_batch.cuda(), pred)\n",
    "        loss.backward(create_graph=True)\n",
    "        train_loss += loss.item() * pred.shape[0]\n",
    "        total_num += pred.shape[0]\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= total_num\n",
    "\n",
    "    print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch, epochs, train_loss))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "bzpudYqD1uT6",
    "outputId": "55eef489-65e7-4bfb-bbe6-51194d44051e",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spectra_generated, params = model(train_batch.cuda())\n",
    "rand = np.random.randint(0, 272)\n",
    "plt.plot(spectra_generated[rand, 0, :].detach().cpu().numpy(), \"r\")\n",
    "plt.plot(train_batch[rand, 0, :], \"b\")\n",
    "print(params[rand])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "o4YyAVHNSrQR",
    "outputId": "e1384f5f-1642-41e9-b990-8208dae26c5a",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nala_spectra_generated, nala_params = model(\n",
    "    nala_spectra.transpose(2, 1).cuda())\n",
    "rand = np.random.randint(0, nala_spectra_generated.shape[0])\n",
    "plt.plot(nala_spectra_generated[rand, 0, :].detach().cpu().numpy(), \"r\")\n",
    "plt.plot(nala_spectra[rand, :, 0], \"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtbZ7_hWqi-j",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# removes 2pi shifts\n",
    "nala_params[:, 1] = nala_params[:, 1] % 2 * np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "HBWPz48wpRKJ",
    "outputId": "1b681f09-4294-4350-c852-7ce3523dcdac",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the learned embeddings\n",
    "embeddings(nala_params.detach().cpu().numpy(),\n",
    "           shape_=image.shape[0:2], figsize=(5, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "PlpTqUciqLcM",
    "outputId": "958b2239-a441-4bdf-c72e-9be17364b0ee",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the actual RGB channels.\n",
    "embeddings(_nala_params.reshape(-1, 3),\n",
    "           shape_=image.shape[0:2], figsize=(5, 1.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **results are much closer to the underlying physics since we enforced them**\n",
    "- The middle parameter is the phase. This is the hardest to learn $\\rightarrow$ this makes sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqWzl7gZsYTE",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Try with a better optimizer AdaHessian\n",
    "\n",
    "- There are better optimizers than ADAM that use second-order information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JL5Xx1J-qXQW",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Feb 26 16:34:00 2021\n",
    "@author: Amir Gholami\n",
    "@coauthor: David Samuel\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class AdaHessian(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements the AdaHessian algorithm from \"ADAHESSIAN: An Adaptive Second OrderOptimizer for Machine Learning\"\n",
    "    Arguments:\n",
    "        params (iterable) -- iterable of parameters to optimize or dicts defining parameter groups\n",
    "        lr (float, optional) -- learning rate (default: 0.1)\n",
    "        betas ((float, float), optional) -- coefficients used for computing running averages of gradient and the squared hessian trace (default: (0.9, 0.999))\n",
    "        eps (float, optional) -- term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional) -- weight decay (L2 penalty) (default: 0.0)\n",
    "        hessian_power (float, optional) -- exponent of the hessian trace (default: 1.0)\n",
    "        update_each (int, optional) -- compute the hessian trace approximation only after *this* number of steps (to save time) (default: 1)\n",
    "        n_samples (int, optional) -- how many times to sample `z` for the approximation of the hessian trace (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr=0.1,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-8,\n",
    "        weight_decay=0.0,\n",
    "        hessian_power=1.0,\n",
    "        update_each=1,\n",
    "        n_samples=1,\n",
    "        average_conv_kernel=False,\n",
    "    ):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(f\"Invalid beta parameter at index 0: {betas[0]}\")\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(f\"Invalid beta parameter at index 1: {betas[1]}\")\n",
    "        if not 0.0 <= hessian_power <= 1.0:\n",
    "            raise ValueError(f\"Invalid Hessian power value: {hessian_power}\")\n",
    "\n",
    "        self.n_samples = n_samples\n",
    "        self.update_each = update_each\n",
    "        self.average_conv_kernel = average_conv_kernel\n",
    "\n",
    "        # use a separate generator that deterministically generates the same `z`s across all GPUs in case of distributed training\n",
    "        self.generator = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            betas=betas,\n",
    "            eps=eps,\n",
    "            weight_decay=weight_decay,\n",
    "            hessian_power=hessian_power,\n",
    "        )\n",
    "        super(AdaHessian, self).__init__(params, defaults)\n",
    "\n",
    "        for p in self.get_params():\n",
    "            p.hess = 0.0\n",
    "            self.state[p][\"hessian step\"] = 0\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Gets all parameters in all param_groups with gradients\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            p for group in self.param_groups for p in group[\"params\"] if p.requires_grad\n",
    "        )\n",
    "\n",
    "    def zero_hessian(self):\n",
    "        \"\"\"\n",
    "        Zeros out the accumulated hessian traces.\n",
    "        \"\"\"\n",
    "\n",
    "        for p in self.get_params():\n",
    "            if (\n",
    "                not isinstance(p.hess, float)\n",
    "                and self.state[p][\"hessian step\"] % self.update_each == 0\n",
    "            ):\n",
    "                p.hess.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_hessian(self):\n",
    "        \"\"\"\n",
    "        Computes the Hutchinson approximation of the hessian trace and accumulates it for each trainable parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        params = []\n",
    "        for p in filter(lambda p: p.grad is not None, self.get_params()):\n",
    "            if (\n",
    "                self.state[p][\"hessian step\"] % self.update_each == 0\n",
    "            ):  # compute the trace only for each `update_each` step\n",
    "                params.append(p)\n",
    "            self.state[p][\"hessian step\"] += 1\n",
    "\n",
    "        if len(params) == 0:\n",
    "            return\n",
    "\n",
    "        if (\n",
    "            self.generator.device != params[0].device\n",
    "        ):  # hackish way of casting the generator to the right device\n",
    "            self.generator = torch.Generator(\n",
    "                params[0].device).manual_seed(2147483647)\n",
    "\n",
    "        grads = [p.grad for p in params]\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            zs = [\n",
    "                torch.randint(0, 2, p.size(),\n",
    "                              generator=self.generator, device=p.device)\n",
    "                * 2.0\n",
    "                - 1.0\n",
    "                for p in params\n",
    "            ]  # Rademacher distribution {-1.0, 1.0}\n",
    "            h_zs = torch.autograd.grad(\n",
    "                grads,\n",
    "                params,\n",
    "                grad_outputs=zs,\n",
    "                only_inputs=True,\n",
    "                retain_graph=i < self.n_samples - 1,\n",
    "            )\n",
    "            for h_z, z, p in zip(h_zs, zs, params):\n",
    "                p.hess += (\n",
    "                    h_z * z / self.n_samples\n",
    "                )  # approximate the expected values of z*(H@z)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional) -- a closure that reevaluates the model and returns the loss (default: None)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        self.zero_hessian()\n",
    "        self.set_hessian()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None or p.hess is None:\n",
    "                    continue\n",
    "\n",
    "                if self.average_conv_kernel and p.dim() == 4:\n",
    "                    p.hess = (\n",
    "                        torch.abs(p.hess)\n",
    "                        .mean(dim=[2, 3], keepdim=True)\n",
    "                        .expand_as(p.hess)\n",
    "                        .clone()\n",
    "                    )\n",
    "\n",
    "                # Perform correct stepweight decay as in AdamW\n",
    "                p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 1:\n",
    "                    state[\"step\"] = 0\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(\n",
    "                        p.data\n",
    "                    )  # Exponential moving average of gradient values\n",
    "                    state[\"exp_hessian_diag_sq\"] = torch.zeros_like(\n",
    "                        p.data\n",
    "                    )  # Exponential moving average of Hessian diagonal square values\n",
    "\n",
    "                exp_avg, exp_hessian_diag_sq = (\n",
    "                    state[\"exp_avg\"],\n",
    "                    state[\"exp_hessian_diag_sq\"],\n",
    "                )\n",
    "                beta1, beta2 = group[\"betas\"]\n",
    "                state[\"step\"] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(p.grad, alpha=1 - beta1)\n",
    "                exp_hessian_diag_sq.mul_(beta2).addcmul_(\n",
    "                    p.hess, p.hess, value=1 - beta2\n",
    "                )\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state[\"step\"]\n",
    "                bias_correction2 = 1 - beta2 ** state[\"step\"]\n",
    "\n",
    "                k = group[\"hessian_power\"]\n",
    "                denom = (\n",
    "                    (exp_hessian_diag_sq / bias_correction2)\n",
    "                    .pow_(k / 2)\n",
    "                    .add_(group[\"eps\"])\n",
    "                )\n",
    "\n",
    "                # make update\n",
    "                step_size = group[\"lr\"] / bias_correction1\n",
    "                p.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxv9kJIOsyq0",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_vector = torch.linspace(0, 10, 100)\n",
    "\n",
    "model = DensePhysLarger(\n",
    "    x_vector, constructor, dense_params=3, model_params=3, verbose=False\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJwjRvbksyq0",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# builds the dataloader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    torch.transpose(spectra_full, 1, 2), batch_size=512, shuffle=True, num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-0ntsQZshWM",
    "outputId": "a0561ed6-4362-417b-d42a-5347dc4ae7ad",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Use AdaHessian\n",
    "\n",
    "optimizer = AdaHessian(model.parameters(), lr=0.1)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    total_num = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for train_batch in dataloader:\n",
    "        pred, _ = model(train_batch.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_func(train_batch.cuda(), pred)\n",
    "        loss.backward(create_graph=True)\n",
    "        train_loss += loss.item() * pred.shape[0]\n",
    "        total_num += pred.shape[0]\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= total_num\n",
    "\n",
    "    print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch, epochs, train_loss))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN_yCo6nshWM",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spectra_generated, params = model(train_batch.cuda())\n",
    "rand = np.random.randint(0, 272)\n",
    "plt.plot(spectra_generated[rand, 0, :].detach().cpu().numpy(), \"r\")\n",
    "plt.plot(train_batch[rand, 0, :], \"b\")\n",
    "print(params[rand])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpYzwfYDshWM",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nala_spectra_generated, nala_params = model(\n",
    "    nala_spectra.transpose(2, 1).cuda())\n",
    "rand = np.random.randint(0, nala_spectra_generated.shape[0])\n",
    "plt.plot(nala_spectra_generated[rand, 0, :].detach().cpu().numpy(), \"r\")\n",
    "plt.plot(nala_spectra[rand, :, 0], \"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLc33BIqshWN",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nala_params[:, 1] = nala_params[:, 1] % 2 * np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6_bQBfVshWN",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the learned embeddings\n",
    "embeddings(nala_params.detach().cpu().numpy(),\n",
    "           shape_=image.shape[0:2], figsize=(5, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfpYeDHhshWN",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the actual RGB channels.\n",
    "embeddings(_nala_params.reshape(-1, 3),\n",
    "           shape_=image.shape[0:2], figsize=(5, 1.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly the best result\n",
    "\n",
    "- It is quite impressive that we can build a feed forward model to fit data to complex functions\n",
    "- This is actually a very hard task for a neural network as frequency and phase are something that cannot be learned easily in convolutions\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Autoencoder Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('m3_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d82ed07f1a000548bae641f7bea0b50abc9c5d353fc085ff35eceda152964b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}